{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Trips and Stations\n",
    "* Create yearly trip parquet files\n",
    "* Create bike dock stations parquet file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import dask.dataframe as dd\n",
    "import pyarrow as pa\n",
    "import logging\n",
    "import requests, json\n",
    "import urllib\n",
    "from geopy.geocoders import Nominatim\n",
    "from geopy.extra.rate_limiter import RateLimiter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_DIR = \"data/\"\n",
    "# CSV_DIR = DATA_DIR + \"tripdata_csv/\"\n",
    "PARQUET_DIR = DATA_DIR + \"tripdata_parquet/\"\n",
    "NY_DIR = PARQUET_DIR + \"NY/\"\n",
    "NJ_DIR = PARQUET_DIR + \"NJ/\"\n",
    "STATIONS_DIR = DATA_DIR + \"stations/\"\n",
    "PARQUET_EXTENSION = \".parquet\"\n",
    "# Station Information GBFS json url\n",
    "STATION_INFO_URL = \"https://gbfs.citibikenyc.com/gbfs/en/station_information.json\"\n",
    "# USGS Elevation Point Query Service url\n",
    "USGS_ELEVATION_POINT_SERVICE_URL = r\"https://nationalmap.gov/epqs/pqs.php?\"\n",
    "\n",
    "logging.basicConfig(level=logging.WARNING)\n",
    "\n",
    "logging.info(\n",
    "    f\"{len(os.listdir(NJ_DIR))} Jersey City files and {len(os.listdir(NY_DIR))} New York City files\"\n",
    ")\n",
    "\n",
    "# schema for parquet files in\n",
    "TRIPDATA_COLUMN_DTYPES = {\n",
    "    \"tripduration\": \"int32\",\n",
    "    \"starttime\": \"datetime64\",\n",
    "    \"stoptime\": \"datetime64\",\n",
    "    \"startstationid\": \"category\",\n",
    "    \"startstationname\": \"category\",\n",
    "    \"startstationlatitude\": \"category\",\n",
    "    \"startstationlongitude\": \"category\",\n",
    "    \"endstationid\": \"category\",\n",
    "    \"endstationname\": \"category\",\n",
    "    \"endstationlatitude\": \"category\",\n",
    "    \"endstationlongitude\": \"category\",\n",
    "    \"bikeid\": \"category\",\n",
    "    \"usertype\": \"category\",\n",
    "    \"birthyear\": \"category\",\n",
    "    \"gender\": \"category\",\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create Trips Parquets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "if not os.path.exists(NY_DIR):\n",
    "    os.makedirs(os.path.dirname(NY_DIR))\n",
    "\n",
    "if not os.path.exists(NJ_DIR):\n",
    "    os.makedirs(os.path.dirname(NJ_DIR))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def merge_monthly_trips(year, directory: str) -> None:\n",
    "    \"\"\"\n",
    "    Creates a merged parquet file from parquet files in a directory\n",
    "    :param year: the year (int) to merge monthly data for. if None, then merge all files in directory\n",
    "    :param directory: a directory containing parquet files with identical schema (column names) across files\n",
    "    :return: None\n",
    "    \"\"\"\n",
    "    if year:\n",
    "        range_start = str(year) + \"-01\"\n",
    "        range_end = str(year) + \"-13\"\n",
    "        month_files = sorted(\n",
    "            [\n",
    "                directory + f\n",
    "                for f in os.listdir(directory)\n",
    "                if range_start <= f <= range_end\n",
    "            ]\n",
    "        )\n",
    "    else:\n",
    "        month_files = sorted(\n",
    "            [\n",
    "                directory + f\n",
    "                for f in os.listdir(directory)\n",
    "                if f.endswith(PARQUET_EXTENSION)\n",
    "            ]\n",
    "        )\n",
    "\n",
    "    parquet_ddfs: list[dd.DataFrame] = []\n",
    "    for month_file in month_files:\n",
    "        if os.path.exists(month_file):\n",
    "            ddf = dd.read_parquet(month_file)\n",
    "            ddf.astype(TRIPDATA_COLUMN_DTYPES)\n",
    "            ddf[\"birthyear\"] = ddf[\"birthyear\"].astype(\n",
    "                \"str\"\n",
    "            )  # some issue with birthyear in particular\n",
    "            parquet_ddfs.append(ddf)\n",
    "\n",
    "    all_trips = dd.concat(parquet_ddfs)\n",
    "    filename = str(year) if year else \"alltrips\"\n",
    "    all_trips.to_parquet(\n",
    "        directory + filename + PARQUET_EXTENSION,\n",
    "        schema={\"birthyear\": pa.string()},\n",
    "        engine=\"pyarrow\",\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "# create parquet file from all trip data (NY)\n",
    "# NOTE run this before running the below cell if you want this large file. running it after will not work\n",
    "merge_monthly_trips(year=None, directory=NY_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "# create yearly trip data parquet files\n",
    "for year in range(2013, 2022):\n",
    "    merge_monthly_trips(year, NY_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# example: read a yearly parquet file (2019)\n",
    "\n",
    "trip_columns = [\n",
    "    \"tripduration\",\n",
    "    \"starttime\",\n",
    "    \"stoptime\",\n",
    "    \"startstationid\",\n",
    "    \"endstationid\",\n",
    "    \"bikeid\",\n",
    "    \"usertype\",\n",
    "    \"birthyear\",\n",
    "    \"gender\",\n",
    "]  # specify columns you want to read\n",
    "test = pd.read_parquet(\n",
    "    NY_DIR + \"2019.parquet\", engine=\"pyarrow\", columns=trip_columns\n",
    ").reset_index()\n",
    "test.drop(test.columns[0], axis=1, inplace=True)  # drop the dask index\n",
    "test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create Stations Parquets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "if not os.path.exists(STATIONS_DIR):\n",
    "    os.makedirs(os.path.dirname(STATIONS_DIR))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def create_stations(year, directory):\n",
    "    \"\"\"\n",
    "    Creates station table for year, saves to parquet file\n",
    "    :param year: year to create stations for using trip data for that year\n",
    "    :param directory: directory with the trip data parquet file\n",
    "    :return: None\n",
    "    \"\"\"\n",
    "    trip_filepath = directory + str(year) + PARQUET_EXTENSION\n",
    "    trips = pd.read_parquet(trip_filepath, engine=\"pyarrow\").reset_index()\n",
    "    trips.drop(trips.columns[0], axis=1, inplace=True)  # drop the dask index\n",
    "\n",
    "    station_columns = [\n",
    "        \"startstationid\",\n",
    "        \"startstationname\",\n",
    "        \"startstationlatitude\",\n",
    "        \"startstationlongitude\",\n",
    "    ]\n",
    "    stations = trips[station_columns]\n",
    "    col_rename = {\n",
    "        \"startstationid\": \"stationid\",\n",
    "        \"startstationname\": \"stationname\",\n",
    "        \"startstationlatitude\": \"latitude\",\n",
    "        \"startstationlongitude\": \"longitude\",\n",
    "    }\n",
    "    stations.rename(columns=col_rename, inplace=True)\n",
    "    stations.drop_duplicates(subset=[\"stationid\"], inplace=True)\n",
    "\n",
    "    stations_filepath = STATIONS_DIR + str(year) + PARQUET_EXTENSION\n",
    "    stations.to_parquet(stations_filepath, engine=\"pyarrow\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "for year in range(2013, 2022):\n",
    "    create_stations(year, NY_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def merge_stations() -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Return merged yearly station files\n",
    "    \"\"\"\n",
    "    stations_dfs = []\n",
    "    stations_files = [\n",
    "        f for f in os.listdir(STATIONS_DIR) if not f.startswith(\"stations\")\n",
    "    ]\n",
    "    for station_file in stations_files:\n",
    "        filepath = STATIONS_DIR + station_file\n",
    "        stations_dfs.append(pd.read_parquet(filepath))\n",
    "\n",
    "    all_stations = pd.concat(stations_dfs)\n",
    "    all_stations.drop_duplicates(subset=[\"stationid\"], inplace=True)\n",
    "\n",
    "    return all_stations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def add_station_capacity(stations: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Adds station capacity info from Citibike GBFS feed\n",
    "    :param stations:\n",
    "    :return: stations with capacity info\n",
    "    \"\"\"\n",
    "    # get station info\n",
    "    url = requests.get(STATION_INFO_URL)\n",
    "    data = json.loads(url.text)\n",
    "    station_details = pd.DataFrame.from_dict(data[\"data\"][\"stations\"])\n",
    "\n",
    "    # extract capacity and merge back to dataframe\n",
    "    station_details = station_details[[\"name\", \"capacity\"]]\n",
    "    station_details.rename(columns={\"name\": \"stationname\"}, inplace=True)\n",
    "\n",
    "    return stations.merge(station_details, how=\"left\", on=\"stationname\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def add_station_geodata(stations: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Adds station geodata info\n",
    "    :param stations:\n",
    "    :return: stations df with geodata info\n",
    "    \"\"\"\n",
    "    logging.debug(\"reverse geocoding boro and neighbourhood, wait 15-20 mins...\")\n",
    "    geolocator = Nominatim(user_agent=\"bikegeocode\")\n",
    "    reverse = RateLimiter(geolocator.reverse, min_delay_seconds=1)\n",
    "    locations_lst = []\n",
    "    for index, row in stations.iterrows():\n",
    "        locations_lst.append(\n",
    "            reverse(\"{}, {}\".format(row[\"latitude\"], row[\"longitude\"])).raw[\"address\"]\n",
    "        )\n",
    "    logging.debug(\"geocode complete, merging...\")\n",
    "    locations = pd.DataFrame(locations_lst, index=stations.stationid).reset_index()\n",
    "    locations = locations[[\"stationid\", \"neighbourhood\", \"suburb\", \"postcode\"]]\n",
    "    locations.rename(columns={\"suburb\": \"boro\", \"postcode\": \"zipcode\"}, inplace=True)\n",
    "    locations = locations.astype(\"category\")\n",
    "\n",
    "    return stations.merge(locations, how=\"left\", on=\"stationid\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def add_elevations(df: pd.DataFrame, lat_column=\"latitude\", lon_column=\"longitude\"):\n",
    "    \"\"\"Queries USGS Elevation Point Service to get elevation values\n",
    "\n",
    "    :param df: dataframe with latitude and longitude\n",
    "    :param lat_column:\n",
    "    :param lon_column:\n",
    "    :return: original df with new elevation column\n",
    "    \"\"\"\n",
    "    elevations = []\n",
    "    i = 0\n",
    "    for lat, lon in zip(df[lat_column], df[lon_column]):\n",
    "        i += 1\n",
    "        logging.debug(f\"Getting elevation {i} for ({lat}, {lon})\")\n",
    "        # define rest query params\n",
    "        params = {\"output\": \"json\", \"x\": lon, \"y\": lat, \"units\": \"Feet\"}\n",
    "\n",
    "        # format query string and return query value\n",
    "        result = requests.get((url + urllib.parse.urlencode(params)))\n",
    "        elevations.append(\n",
    "            result.json()[\"USGS_Elevation_Point_Query_Service\"][\"Elevation_Query\"][\n",
    "                \"Elevation\"\n",
    "            ]\n",
    "        )\n",
    "\n",
    "    df[\"elevation_ft\"] = elevations\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# merge yearly stations data, get capacity, get geodata, save\n",
    "# TODO get elevation\n",
    "stations = merge_stations()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "stations = add_station_capacity(stations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "stations = add_station_geodata(stations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "stations = add_elevations(stations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "stations.to_csv(STATIONS_DIR + \"stations\" + \".csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "stations[\"elevation_ft\"] = stations[\"elevation_ft\"].astype(\"str\")\n",
    "stations.to_parquet(STATIONS_DIR + \"stations\" + PARQUET_EXTENSION, engine=\"pyarrow\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# example: read stations (all stations seen across all years)\n",
    "stations = pd.read_parquet(\n",
    "    STATIONS_DIR + \"stations\" + PARQUET_EXTENSION, engine=\"pyarrow\"\n",
    ")\n",
    "stations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fixing Boros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>stationid</th>\n",
       "      <th>stationname</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>capacity</th>\n",
       "      <th>neighbourhood</th>\n",
       "      <th>boro</th>\n",
       "      <th>zipcode</th>\n",
       "      <th>elevation_ft</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>455.0</td>\n",
       "      <td>1 Ave &amp; E 44 St</td>\n",
       "      <td>40.750020</td>\n",
       "      <td>-73.969053</td>\n",
       "      <td>59.0</td>\n",
       "      <td>Turtle Bay</td>\n",
       "      <td>Manhattan</td>\n",
       "      <td>10017-6927</td>\n",
       "      <td>46.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>434.0</td>\n",
       "      <td>9 Ave &amp; W 18 St</td>\n",
       "      <td>40.743174</td>\n",
       "      <td>-74.003664</td>\n",
       "      <td>60.0</td>\n",
       "      <td>Chelsea District</td>\n",
       "      <td>Manhattan</td>\n",
       "      <td>10019</td>\n",
       "      <td>15.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>491.0</td>\n",
       "      <td>E 24 St &amp; Park Ave S</td>\n",
       "      <td>40.740964</td>\n",
       "      <td>-73.986022</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Manhattan Community Board 5</td>\n",
       "      <td>Manhattan</td>\n",
       "      <td>10010</td>\n",
       "      <td>34.87</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>384.0</td>\n",
       "      <td>Fulton St &amp; Waverly Ave</td>\n",
       "      <td>40.683178</td>\n",
       "      <td>-73.965964</td>\n",
       "      <td>31.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Brooklyn</td>\n",
       "      <td>11238</td>\n",
       "      <td>78.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>474.0</td>\n",
       "      <td>5 Ave &amp; E 29 St</td>\n",
       "      <td>40.745168</td>\n",
       "      <td>-73.986831</td>\n",
       "      <td>56.0</td>\n",
       "      <td>Midtown South</td>\n",
       "      <td>Manhattan</td>\n",
       "      <td>10035</td>\n",
       "      <td>41.55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1425</th>\n",
       "      <td>3685.0</td>\n",
       "      <td>Prospect Park - 5 Year Anniversary Celebration</td>\n",
       "      <td>40.660652</td>\n",
       "      <td>-73.964590</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Brooklyn</td>\n",
       "      <td>11225</td>\n",
       "      <td>85.71</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1426</th>\n",
       "      <td>3695.0</td>\n",
       "      <td>E 5 St &amp; 2 Ave</td>\n",
       "      <td>40.726870</td>\n",
       "      <td>-73.989190</td>\n",
       "      <td>NaN</td>\n",
       "      <td>East Village</td>\n",
       "      <td>Manhattan</td>\n",
       "      <td>10003</td>\n",
       "      <td>36.09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1427</th>\n",
       "      <td>3700.0</td>\n",
       "      <td>E 87 St &amp; 3 Ave</td>\n",
       "      <td>40.779406</td>\n",
       "      <td>-73.953336</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Carnegie Hill</td>\n",
       "      <td>Manhattan</td>\n",
       "      <td>10028</td>\n",
       "      <td>79.35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1428</th>\n",
       "      <td>3805.0</td>\n",
       "      <td>E 80 St &amp; Park Ave</td>\n",
       "      <td>40.776173</td>\n",
       "      <td>-73.959757</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Manhattan Community Board 8</td>\n",
       "      <td>Manhattan</td>\n",
       "      <td>10075</td>\n",
       "      <td>79.28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1429</th>\n",
       "      <td>3747.0</td>\n",
       "      <td>E 84 St &amp; 3 Ave</td>\n",
       "      <td>40.777554</td>\n",
       "      <td>-73.955128</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Manhattan</td>\n",
       "      <td>10028</td>\n",
       "      <td>78.35</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1423 rows Ã— 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      stationid                                     stationname   latitude  \\\n",
       "0         455.0                                 1 Ave & E 44 St  40.750020   \n",
       "1         434.0                                 9 Ave & W 18 St  40.743174   \n",
       "2         491.0                            E 24 St & Park Ave S  40.740964   \n",
       "3         384.0                         Fulton St & Waverly Ave  40.683178   \n",
       "4         474.0                                 5 Ave & E 29 St  40.745168   \n",
       "...         ...                                             ...        ...   \n",
       "1425     3685.0  Prospect Park - 5 Year Anniversary Celebration  40.660652   \n",
       "1426     3695.0                                  E 5 St & 2 Ave  40.726870   \n",
       "1427     3700.0                                 E 87 St & 3 Ave  40.779406   \n",
       "1428     3805.0                              E 80 St & Park Ave  40.776173   \n",
       "1429     3747.0                                 E 84 St & 3 Ave  40.777554   \n",
       "\n",
       "      longitude  capacity                neighbourhood       boro     zipcode  \\\n",
       "0    -73.969053      59.0                   Turtle Bay  Manhattan  10017-6927   \n",
       "1    -74.003664      60.0             Chelsea District  Manhattan       10019   \n",
       "2    -73.986022       NaN  Manhattan Community Board 5  Manhattan       10010   \n",
       "3    -73.965964      31.0                          NaN   Brooklyn       11238   \n",
       "4    -73.986831      56.0                Midtown South  Manhattan       10035   \n",
       "...         ...       ...                          ...        ...         ...   \n",
       "1425 -73.964590       NaN                          NaN   Brooklyn       11225   \n",
       "1426 -73.989190       NaN                 East Village  Manhattan       10003   \n",
       "1427 -73.953336       NaN                Carnegie Hill  Manhattan       10028   \n",
       "1428 -73.959757       NaN  Manhattan Community Board 8  Manhattan       10075   \n",
       "1429 -73.955128       NaN                          NaN  Manhattan       10028   \n",
       "\n",
       "     elevation_ft  \n",
       "0            46.8  \n",
       "1            15.9  \n",
       "2           34.87  \n",
       "3            78.1  \n",
       "4           41.55  \n",
       "...           ...  \n",
       "1425        85.71  \n",
       "1426        36.09  \n",
       "1427        79.35  \n",
       "1428        79.28  \n",
       "1429        78.35  \n",
       "\n",
       "[1423 rows x 9 columns]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stations = pd.read_parquet(\n",
    "    STATIONS_DIR + \"stations\" + PARQUET_EXTENSION, engine=\"pyarrow\"\n",
    ")\n",
    "# drop stations without any geo data (coordiantes, boro, zip, etc...)\n",
    "stations.drop(\n",
    "    index=stations.loc[stations.boro.isna() & stations.zipcode.isna()].index.tolist(),\n",
    "    inplace=True,\n",
    ")\n",
    "\n",
    "# drop station missing boro with zip in JC\n",
    "stations.drop(\n",
    "    index=stations.loc[stations.zipcode == \"07311\"].index.tolist(), inplace=True\n",
    ")\n",
    "\n",
    "# impute missing boros using zipcode\n",
    "zip_boro_dic = {\n",
    "    \"11207\": \"Brooklyn\",\n",
    "    \"11217\": \"Brooklyn\",\n",
    "    \"11201\": \"Brooklyn\",\n",
    "    \"11231\": \"Brooklyn\",\n",
    "    \"11238\": \"Brooklyn\",\n",
    "    \"11213\": \"Brooklyn\",\n",
    "    \"11221\": \"Brooklyn\",\n",
    "    \"11201-1832\": \"Brooklyn\",\n",
    "    \"11237\": \"Brooklyn\",\n",
    "    \"11205\": \"Brooklyn\",\n",
    "    \"11251\": \"Brooklyn\",\n",
    "    \"11227\": \"Brooklyn\",\n",
    "    \"11222\": \"Brooklyn\",\n",
    "    \"11216\": \"Brooklyn\",\n",
    "    \"11220\": \"Brooklyn\",\n",
    "    \"11215\": \"Brooklyn\",\n",
    "    \"11209\": \"Brooklyn\",\n",
    "    \"112321\": \"Brooklyn\",  # possibly a typo, determined by other rows with same zip\n",
    "    \"11232\": \"Brooklyn\",\n",
    "    \"10459\": \"The Bronx\",\n",
    "    \"10456\": \"The Bronx\",\n",
    "    \"10451\": \"The Bronx\",\n",
    "    \"10457\": \"The Bronx\",\n",
    "}\n",
    "stations = stations.astype({\"boro\": \"string\"})  # change type to allow string imputation\n",
    "stations.boro = stations.boro.fillna(stations.zipcode.map(zip_boro_dic))\n",
    "\n",
    "# merge queens county and queens\n",
    "stations.loc[stations.boro == \"Queens County\", \"boro\"] = \"Queens\"\n",
    "\n",
    "# overwrite parquet file\n",
    "stations.to_parquet(STATIONS_DIR + \"stations\" + PARQUET_EXTENSION, engine=\"pyarrow\")\n",
    "\n",
    "stations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# confirm changes\n",
    "stations = pd.read_parquet(\n",
    "    STATIONS_DIR + \"stations\" + PARQUET_EXTENSION, engine=\"pyarrow\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 1423 entries, 0 to 1429\n",
      "Data columns (total 9 columns):\n",
      " #   Column         Non-Null Count  Dtype   \n",
      "---  ------         --------------  -----   \n",
      " 0   stationid      1423 non-null   float64 \n",
      " 1   stationname    1423 non-null   object  \n",
      " 2   latitude       1423 non-null   float64 \n",
      " 3   longitude      1423 non-null   float64 \n",
      " 4   capacity       1210 non-null   float64 \n",
      " 5   neighbourhood  862 non-null    category\n",
      " 6   boro           1423 non-null   string  \n",
      " 7   zipcode        1419 non-null   category\n",
      " 8   elevation_ft   1423 non-null   object  \n",
      "dtypes: category(2), float64(4), object(2), string(1)\n",
      "memory usage: 100.9+ KB\n"
     ]
    }
   ],
   "source": [
    "stations.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Manhattan      664\n",
       "Brooklyn       422\n",
       "The Bronx      176\n",
       "Queens         159\n",
       "Ville-Marie      2\n",
       "Name: boro, dtype: Int64"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stations.boro.value_counts()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
